# Defining AI 

How would I define AI now? 

AI is the process of teaching a machine how to accomplish a task via the method of exposing it to large datasets of correct and incorrect ways to accomplish this task. The AI model will then train on this dataset and learn the correct way of accomplishing this task. 

There are stages to AI: 

- Narrow/ Weak AI 
- Artificial General Intelligence 
- Artificial Superintellegence

Currently we only fall under the first category.

AGI is defined by an AI model being able to transfer it's expertise in a problem domain to a new problem domain, much like human reasoning. 

Typical tasks performed by AI are 

- Learning 
- Scheduling 
- Logical problem solving 
- Identifying data trends 
- Reasoning 
- Decision making 

There have been many stages to AI 

1950s: Machines mimicing cognitive functions
1980s: Machine Learning 
2000s: Deep Learning 


Definitions given in th electure: 

- The science and engineering of making intelligent machines (McCarthy, 1995, p.12)
- [The Automation of] activities that we associate with human thinking, activities such as decision making, problem solving, learning... (Bellman, 1978, p.11)
- The study of how to make computers do things at which, at the moment, people are better (Rich and Kight, 1991, p.27)
- The study of the computations that make it possible to percieve, reason, and act (Winston, 1992, p.43)
- The branch of computer science that is concerned with the automation of intelligent behavior (Luger and Stubblefield, 1993, p.68)
- The subfield of Computer Science devoted to developing programs that enable computers to display behavior that can (broadly) be characterized as intelligent (Russell and Norvig, 2010, p.1)